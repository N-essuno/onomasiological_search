{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.corpus.reader import Synset\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:01:40.715393Z",
     "start_time": "2024-03-21T11:01:40.701705Z"
    }
   },
   "id": "6cd764fb30b2e96a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amato\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "embedder = spacy.load(\"en_core_web_md\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:38:31.367555Z",
     "start_time": "2024-03-21T10:38:29.180618Z"
    }
   },
   "id": "ca518ff0c70050d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                door  \\\n0  A construction used to divide two rooms, tempo...   \n1       It's an opening, it can be opened or closed.   \n2  An object that divide two room, closing an hol...   \n3         Usable for access from one area to another   \n4  Structure that delimits an area and allows acc...   \n\n                                             ladybug  \\\n0  small flying insect, typically red with black ...   \n1  It is an insect, it has wings, red with black ...   \n2  An insect that can fly. It has red or orange c...   \n3                       Small insect with a red back   \n4                          Small round flying insect   \n\n                                                pain  \\\n0           A feeling of physical or mental distress   \n1  It is a feeling, physical or emotional. It is ...   \n2  A felling that couscious beings can experince ...   \n3    Concept that describes a suffering living being   \n4                     Feeling of physical discomfort   \n\n                                          blurriness  \n0                                 sight out of focus  \n1  It is the absence of definite borders, shapele...  \n2  A sensation felt when you can't see clearly th...  \n3                                  Lack of sharpness  \n4     Characteristic of lack of clarity or precision  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>door</th>\n      <th>ladybug</th>\n      <th>pain</th>\n      <th>blurriness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A construction used to divide two rooms, tempo...</td>\n      <td>small flying insect, typically red with black ...</td>\n      <td>A feeling of physical or mental distress</td>\n      <td>sight out of focus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It's an opening, it can be opened or closed.</td>\n      <td>It is an insect, it has wings, red with black ...</td>\n      <td>It is a feeling, physical or emotional. It is ...</td>\n      <td>It is the absence of definite borders, shapele...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An object that divide two room, closing an hol...</td>\n      <td>An insect that can fly. It has red or orange c...</td>\n      <td>A felling that couscious beings can experince ...</td>\n      <td>A sensation felt when you can't see clearly th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Usable for access from one area to another</td>\n      <td>Small insect with a red back</td>\n      <td>Concept that describes a suffering living being</td>\n      <td>Lack of sharpness</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Structure that delimits an area and allows acc...</td>\n      <td>Small round flying insect</td>\n      <td>Feeling of physical discomfort</td>\n      <td>Characteristic of lack of clarity or precision</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definitions = pd.read_csv('resources/definitions.tsv', sep='\\t')\n",
    "definitions.head()\n",
    "\n",
    "# remove index from the dataframe (for each row it is the first element)\n",
    "definitions = definitions.iloc[:, 1:]\n",
    "definitions.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:48.038603Z",
     "start_time": "2024-03-21T09:14:47.994616Z"
    }
   },
   "id": "e565075752925fbb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# convert the dataframe to a dictionary for easier access\n",
    "definitions_dict: Dict[str, List[str]] = {}\n",
    "for column in definitions.columns:\n",
    "    definitions_dict[column] = definitions[column].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:48.054633Z",
     "start_time": "2024-03-21T09:14:48.040599Z"
    }
   },
   "id": "f7cc058805ea9006"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- DOOR: \n",
      "\tA construction used to divide two rooms, temporarily closing the passage between them\n",
      "- LADYBUG: \n",
      "\tsmall flying insect, typically red with black spots with six legs\n",
      "- PAIN: \n",
      "\tA feeling of physical or mental distress\n",
      "- BLURRINESS: \n",
      "\tsight out of focus\n"
     ]
    }
   ],
   "source": [
    "# print every word and one of its definitions\n",
    "for word in definitions_dict:\n",
    "    print(f'- {word.upper()}: \\n\\t{definitions_dict[word][0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:48.069796Z",
     "start_time": "2024-03-21T09:14:48.056635Z"
    }
   },
   "id": "7c73b36e75d51850"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Function to calculate the signature of the definitions\n",
    "\n",
    "For each word, the signature is a list of words that are present in the definitions of the word. The words are lemmatized and the punctuation and stop words are removed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11a0ed943058e817"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_sentence(sentence: str) -> List[str]:\n",
    "    # convert to list of words\n",
    "    word_list = sentence.split()\n",
    "    # convert to lower case\n",
    "    word_list = [word.lower() for word in word_list]\n",
    "    # tokenize the words and remove punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_list = tokenizer.tokenize(' '.join(word_list))\n",
    "    # remove stop words using the nltk stop words list\n",
    "    word_list = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    # lemmatize the words\n",
    "    word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "    return word_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:48.085410Z",
     "start_time": "2024-03-21T09:14:48.073312Z"
    }
   },
   "id": "5401e697a743a6a5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# extract synset of 10 most frequent words in definitions\n",
    "def get_synsets_for_word(signature: List[str]) -> List[Synset]:\n",
    "    # calculate words frequency for a definition signature\n",
    "    word_frequency = Counter(signature)\n",
    "    most_common_words: List[Tuple] = word_frequency.most_common(10)\n",
    "    \n",
    "    # get 10 most common nouns from most common words\n",
    "    most_common_nouns = [word_tuple for word_tuple in most_common_words if wn.synsets(word_tuple[0]) and wn.synsets(word_tuple[0])[0].pos() == 'n']\n",
    "    \n",
    "    print(most_common_nouns)\n",
    "    \n",
    "    # get the synsets for the most common nouns\n",
    "    synsets: List[Synset] = [wn.synsets(word_tuple[0])[0] for word_tuple in most_common_nouns]\n",
    "    return synsets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:48.101251Z",
     "start_time": "2024-03-21T09:14:48.087385Z"
    }
   },
   "id": "feaa5efcf095a0aa"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['construction', 'used', 'divide', 'two', 'room', 'temporarily', 'closing', 'passage']\n",
      "[('construction', 1), ('divide', 1), ('two', 1), ('room', 1), ('closing', 1), ('passage', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Synset('construction.n.01'),\n Synset('divide.n.01'),\n Synset('two.n.01'),\n Synset('room.n.01'),\n Synset('shutting.n.01'),\n Synset('passage.n.01')]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "door_def_1 = definitions_dict['door'][0]\n",
    "signature = clean_sentence(door_def_1)\n",
    "print(signature)\n",
    "get_synsets_for_word(signature)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:14:50.105553Z",
     "start_time": "2024-03-21T09:14:48.105605Z"
    }
   },
   "id": "23078ed7d5089db1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO\n",
    "\n",
    "Starting from the synsets of the most common words in the definitions, navigate the WordNet graph to find the synset with maximum overlap between definition signature and synset signature."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25a1e2d890adaf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Approach 1: find the synset with maximum overlap between definition signature and synset signature"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f385ead946dc03f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_synset_signature(synset: Synset) -> List[str]:\n",
    "    gloss: List[str] = synset.definition().split()\n",
    "    examples: List[str] = \" \".join(synset.examples()).split()\n",
    "    synset_signature = clean_sentence(\" \".join(gloss + examples))\n",
    "    return synset_signature\n",
    "\n",
    "def get_max_overlap_synset(definition: str) -> Synset:\n",
    "    max_overlap = 0\n",
    "    max_overlap_synset = None\n",
    "    signature = clean_sentence(definition)\n",
    "    # for each synset in wordnet\n",
    "    for synset in wn.all_synsets():\n",
    "        # get the signature of the synset\n",
    "        synset_signature = get_synset_signature(synset)\n",
    "        # calculate the overlap between the definition signature and the synset signature\n",
    "        overlap = len(set(signature).intersection(set(synset_signature)))\n",
    "        # if the overlap is greater than the maximum overlap, update the maximum overlap and the synset\n",
    "        if overlap > max_overlap:\n",
    "            max_overlap = overlap\n",
    "            max_overlap_synset = synset\n",
    "    return max_overlap_synset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T09:58:02.461878Z",
     "start_time": "2024-03-21T09:58:02.443563Z"
    }
   },
   "id": "422f263fab25664",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('caterpillar.n.02')\n"
     ]
    }
   ],
   "source": [
    "door_synset = get_max_overlap_synset(door_def_1)\n",
    "print(door_synset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:06:54.983159Z",
     "start_time": "2024-03-21T09:58:04.564172Z"
    }
   },
   "id": "df1fd676573410db",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a large tracked vehicle that is propelled by two endless metal belts; frequently used for moving earth in construction and farm work\n"
     ]
    }
   ],
   "source": [
    "print(door_synset.definition())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:12:27.901181Z",
     "start_time": "2024-03-21T10:12:27.885280Z"
    }
   },
   "id": "2a30966e9480a138",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Approach 2: starting from the most general name synset explore the graph following the branch with maximum cosine similarity between the definition signature and the synset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84924f126aed500d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'A construction used to divide two rooms, temporarily closing the passage between them':\n",
      "construction used divide two room temporarily closing passage\n"
     ]
    }
   ],
   "source": [
    "def embed_sentence(sentence: str) -> Doc:\n",
    "    sentence = \" \".join(clean_sentence(sentence))\n",
    "    return embedder(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:16:43.827487Z",
     "start_time": "2024-03-21T11:16:43.791795Z"
    }
   },
   "id": "8328455ed2ef455d",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_synset_embedding(synset: Synset) -> Doc:    \n",
    "    # Concatenate the lemma names to form a text representation of the synset\n",
    "    synset_lemmas = ' '.join(lemma.name().replace('_', ' ') for lemma in synset.lemmas())\n",
    "    synset_gloss = synset.definition()\n",
    "    synset_examples = ' '.join(example for example in synset.examples())\n",
    "    synset_signature = synset_lemmas + ' ' + synset_gloss + ' ' + synset_examples\n",
    "\n",
    "    # Create a Doc from the synset text\n",
    "    synset_doc = embedder(\" \".join(clean_sentence(synset_signature)))\n",
    "\n",
    "    return synset_doc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:08:45.886469Z",
     "start_time": "2024-03-21T14:08:45.869169Z"
    }
   },
   "id": "860a69ea885b94f6",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.08536926363462019\n"
     ]
    }
   ],
   "source": [
    "door_synset = wn.synsets('door')[0]\n",
    "door_synset_embedding = get_synset_embedding(door_synset)\n",
    "\n",
    "# cosine similarity between the word and the synset\n",
    "print(door_synset_embedding.similarity(embedder('door')))\n",
    "print(door_synset_embedding.similarity(embedder('penguin')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T11:06:40.387505Z",
     "start_time": "2024-03-21T11:06:40.346810Z"
    }
   },
   "id": "9c8071d5cabd27f5",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def find_best_synset(definition: str) -> Synset:\n",
    "    # Compute the target definition embedding\n",
    "    target_doc = embed_sentence(definition)\n",
    "\n",
    "    # synset for the current node in the graph, initialized to the most general name synset\n",
    "    current_synset = wn.synset('entity.n.01')\n",
    "    # flag to check if the current synset is a leaf\n",
    "    reached_leaf = False\n",
    "    # holds the highest similarity between the hyponyms of current synset and the target definition\n",
    "    highest_similarity = 0\n",
    "    # similarity between the current synset and the target definition\n",
    "    previous_similarity = -1\n",
    "    # similarity between the target definition and the current synset\n",
    "    current_similarity = 0\n",
    "    # hyponym with the highest similarity to the target definition\n",
    "    best_hyponym = None\n",
    "    \n",
    "    threshold = 0.001\n",
    "\n",
    "    while not reached_leaf and current_similarity > previous_similarity + threshold:\n",
    "        print(current_synset)\n",
    "        \n",
    "        # Get the hyponyms of the current synset\n",
    "        hyponyms = current_synset.hyponyms()\n",
    "\n",
    "        # If the current synset has no hyponyms, set the reached_leaf flag to True\n",
    "        if not hyponyms:\n",
    "            reached_leaf = True\n",
    "        else:\n",
    "            for hyponym in hyponyms:\n",
    "                # Get the embedding of the hyponym\n",
    "                hyponym_embedding = get_synset_embedding(hyponym)\n",
    "        \n",
    "                # Compute the similarity between the target definition and the current hyponym\n",
    "                hyponym_similarity = target_doc.similarity(hyponym_embedding)\n",
    "                \n",
    "                # If the similarity is greater than the highest similarity, update the highest similarity and the current synset\n",
    "                if hyponym_similarity > highest_similarity:\n",
    "                    highest_similarity = hyponym_similarity\n",
    "                    best_hyponym = hyponym\n",
    "            # now we found the best hyponym for the current synset\n",
    "            previous_similarity = current_similarity\n",
    "            current_synset = best_hyponym\n",
    "            current_similarity = highest_similarity\n",
    "\n",
    "    return current_synset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:07:28.810118Z",
     "start_time": "2024-03-21T14:07:28.794793Z"
    }
   },
   "id": "faea877bcd6f2ebb",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('entity.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('relation.n.01')\n",
      "Synset('connection.n.01')\n",
      "Synset('communication.n.03')\n",
      "Synset('communication.n.03')\n"
     ]
    }
   ],
   "source": [
    "door_synset = find_best_synset(definitions_dict['door'][3])\n",
    "print(door_synset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T14:08:49.947832Z",
     "start_time": "2024-03-21T14:08:49.062523Z"
    }
   },
   "id": "17c5524cb6cfe8c1",
   "execution_count": 80
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
